{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> Προπαρασκευή 3ου εργαστηρίου</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Επειδή ο κώδικας ήταν οργανωμένος σε συγκεκριμένα αρχεία και η εκτελεσή του δεν γινόταν μέσω jupyter notebook στη αναφορά δεν περιέχεται ο περισσότερος κώδικας που συμπληρώθηκε. Η αναφορά στοχεύει στην εξήγηση του, την παρουσίαση των αποτελεσμάτων και στην απάντηση των ζητούμενων ερωτήσεων. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h2> Εισαγωγή </h2></center>\n",
    "\n",
    "Σκοπός της προπαρασκευής είναι η υλοποίηση ενός μοντέλου για την επεξεργασία και κατηγοριοποίηση κειμένων, με την χρήση βαθιών νευρωνικών δικτύων (Deep Neural Networks - DNN). Για την ανάπτυξη των μοντέλων χρησιμοποιήθηκε η βιβλιοθήκη PyTorch. Αρχικά, χρησιμοποιώντας προ-εκπαιδευμένες\n",
    "διανυσματικές αναπαραστάσεις λέξεων (pretrained word embeddings), θα δημιουργήσουμε\n",
    "αναπαραστάσεις για κάθε κείμενο. Στη συνέχεια, θα χρησιμοποιήσουμε τις αναπαραστάσεις των\n",
    "κειμένων, ώστε να κάνουμε την κατηγοριοποίηση. Στόχος είναι να εκπαιδεύσουμε μοντέλα, τα οποία\n",
    "θα μπορούν να κάνουν ανάλυση συναισθήματος (sentiment analysis) σε προτάσεις. Μας παρέχονται\n",
    "2 σύνολα δεδομένων .\n",
    "- Sentence Polarity Dataset 2 [Pang and Lee, 2005]. To dataset αυτό περιέχει 5331 θετικές\n",
    "και 5331 αρνητικές κριτικές ταινιών, από το Rotten Tomatoes και είναι binary-classification\n",
    "πρόβλημα (positive, negative).\n",
    "- Semeval 2017 Task4-A 3 [Rosenthal et al., 2017]. To dataset αυτό περιέχει tweets τα οποία\n",
    "είναι κατηγοριοποιημένα σε 3 κλάσεις (positive, negative, neutral) με 49570 παραδείγματα\n",
    "εκπαίδευσης και 12284 παραδείγματα αξιολόγησης."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2> Επιλογή pretrained word embeddings </h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Για την συγκεκριμένη άσκηση θα χρησιμοποιηθούν τα παρακάτω embeddings:\n",
    "- Glove embeddings το οποίο περιέχει ακόμα και 50-διάστατα embeddings έχοντας έτσι λιγότερες υπολογιστικές απαιτήσεις.\n",
    "- FastText embeddings τα οποία όμως είναι διαθέσιμα μόνο σε 300 διαστάσεις."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Σε όλη την παρακάτω ανάλυση χρησιμοποιήθηκαν τα glove embeddings των 50 διαστάσεων. Στο τέλος θα παρουσιαστεί η επίδοση του μοντέλου και σε άλλα embeddings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2> 1. Προεπεξεργασία Δεδομένων </h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Για την προεπεξεργασία των δεδομένων μας θα κληρονομήσουμε τις κλάσεις __torch.utils.data.Dataset__ και __torch.utils.data.Dataloader__ του pytorch. Συγκεκριμένα, η πρώτη μετατρέπει κάθε παράδειγμα στην μορφή που απαιτείται για την εκπαίδευση του νερωνικού δικτύου ενώ η δεύτερη χρησιμοποιώντας ένα στιγμιότυπο της κλάσης Dataset μετατρέπει τα παραδείγματα σε torch Tensors και τα οργανώνει σε mini-batches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Κωδικοποίηση επισημειώσεων (Labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Σε αυτό το στάδιο θα μετατρέψουμε τα labels από κείμενα (positive, neutral, negative για το Semeval2017A dataset και positive, negative για το MR dataset) σε αριθμούς ώστε να μπορούν να εισαχθούν μετά στο νευρωνικό δίκτυο. Η μετατροπή αυτή γίνεται χρησιμοποιώντας το LabelEncoder του sklearn όπως φαίνεται και παρακάτω σε μία τυχαία λίστα από labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive' 'negative' 'negative' 'negative' 'positive' 'positive'\n",
      " 'negative' 'positive' 'negative' 'negative']\n",
      "[1 0 0 0 1 1 0 1 0 0]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import choice\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Generate 10 random labels. \n",
    "labels = choice(['positive', 'negative'], 10)\n",
    "print(labels)\n",
    "# Create a new label encoder.\n",
    "le = LabelEncoder()\n",
    "# Encode labels\n",
    "encoded_labels = le.fit_transform(labels) \n",
    "print(encoded_labels)\n",
    "# compute number of classes made by the encoder\n",
    "n_classes = le.classes_.size\n",
    "print(n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Παρακάτω βλέπουμε τα πρώτα 10 labels από τα δεδομένα εκπαίδευσης και την αντιστοιχία τους σε αριθμούς για το MR dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"photos/EX1_MR.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Παρακάτω βλέπουμε τα πρώτα 10 labels από τα δεδομένα εκπαίδευσης και την αντιστοιχία τους σε αριθμούς για το Semevel2017A dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"photos/EX1_Sem.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Λεκτική Ανάλυση (Tokenization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Στη συνέχεια πρέπει να μετατρέψουμε τα δεδομένα μας από κείμενα σε ακολουθίες από tokens. Αυτό θα συμβεί στην αρχικοποίηση της κλάσης __SentenceDataset__ η οποία κληρονομεί την κλάση torch.utils.data.Dataset. Ανάλογα με τις ιδιαιτερότητες του dataset μας μπορούμε να χρησιμοποιήσουμε διαφορετικούς tokenizers. Για το MR dataset που δεν είναι σε τόσο \"κακή\" μορφή τα κείμενα (σε σχέση με τα tweets) μπορούμε να κάνουμε κάποιο απλό tokenize χωρίς την χρήση κάποιας βιβλιοθήκης. Αντίθετα, για το Semeval 2017A dataset που περιέχει tweets θα χρησιμοποιήσουμε τον TweetTokenizer του nltk. Παρακάτω φαίνεται η χρήση τους στην πρώτη πρόταση από κάθε dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Sentence Polarity dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gorgeously', 'elaborate', 'continuation', 'lord', 'rings', 'trilogy', 'huge', 'column', 'words', 'cannot', 'adequately', 'describe', 'cowriterdirector', 'peter', 'jacksons', 'expanded', 'vision', 'tolkiens', 'middleearth']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "# sample review\n",
    "text = \"the gorgeously elaborate continuation of ' the lord of the rings ' trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth\"\n",
    "# split into tokens by white space\n",
    "tokens = text.split()\n",
    "# remove punctuation from each token\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "tokens = [w.translate(table) for w in tokens]\n",
    "# remove remaining tokens that are not alphabetic\n",
    "tokens = [word for word in tokens if word.isalpha()]\n",
    "# filter out stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = [w for w in tokens if not w in stop_words]\n",
    "# filter out short tokens\n",
    "tokens = [word for word in tokens if len(word) > 1]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Semeval 2017A dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ang', 'sarap', 'mging', 'panganay', '.', 'Pag', 'ikaw', 'may', 'kylngan', 'wala', 'kang', 'matakbuhan', '.', ':D', '101', '#realtalk', '#grind', '#onyourown']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "# sample tweet\n",
    "text = \"ang sarap mging panganay. Pag ikaw may kylngan wala kang matakbuhan.:D 101 #realtalk #grind #onyourown\"\n",
    "tweetToken = TweetTokenizer()\n",
    "tokens = tweetToken.tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Παρακάτω βλέπουμε τα πρώτα 10 tokenized παραδείγματα από τα δεδομένα εκπαίδευσης για το MR dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"photos/EX2_MR.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Παρακάτω βλέπουμε τα πρώτα 10 tokenized παραδείγματα από τα δεδομένα εκπαίδευσης για το Semeval2017A dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"photos/EX2_Sem.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Κωδικοποίηση Παραδειγμάτων (Λέξεων)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Τώρα πρέπει να υλοποιήσουμε την μέθοδο \\__getitem__ της παραπάνω κλάσης η οποία δέχεται ένα index και επιστρέφει τα εξής:\n",
    "- την κωδικοποιημένη μορφή μίας πρότασης (αντιστοίχηση token στο id του embedding)\n",
    "- το id της επισημείωσης \n",
    "- το πραγματικό μήκος της πρότασης (δηλαδή εξαιρουμένων των μηδενικών στοιχείων)\n",
    "Αρχικά, επειδή πρέπει όλα τα παραδείγματα να έχουν ίδιο μήκος πρέπει να βρούμε ένα κατάλληλο μήκος που να καλύπτει την πλειοψηφία των προτάσεων, αγνοώντας τους outliers. Παρακάτω βλέπουμε το scatterplot του μεγέθους όλων των προτάσεων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings...\n",
      "Loaded word embeddings from cache.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run bestLength.py MR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings...\n",
      "Loaded word embeddings from cache.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run bestLength.py Semeval2017A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Μπορούμε για να ελέγξουμε ότι ο κώδικας είναι σωστός για ένα ενδεικτικό word2idx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 5. 2. 1. 0. 0. 0. 0.]\n",
      "1\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# A sample word2idx.\n",
    "word2idx = {'I':3, 'love':5, 'hate':4, 'this':2, 'movie':1, 'cat':6, '<unk>':0}\n",
    "# A sample tokenized text\n",
    "text = ['I', 'love', 'this', 'movie', 'a', 'lot']\n",
    "# Length that should match\n",
    "bestLength = 8\n",
    "# Initialize the ndarray that will contain the encoded form of a sentence.\n",
    "example = np.zeros(bestLength)\n",
    "for i in range(min(bestLength, len(text))):\n",
    "    if text[i] in word2idx:\n",
    "        example[i] = word2idx[text[i]]\n",
    "    else:\n",
    "        example[i] = word2idx[\"<unk>\"]\n",
    "label = 1\n",
    "length = len(text)\n",
    "# print the results\n",
    "print(example)\n",
    "print(label)\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Παρατηρήσαμε στο scatterplot ότι ένα καλό μέγεθος είναι το 50 για το MR dataset και το 40 για το Semeval2017A dataset. Αφού υλοποιήσουμε λοιπόν την ζητούμενη μέθοδο (αναλυτικά σχόλια υπάρχουν στον κώδικα) όπως παραπάνω βλέπουμε παρακάτω 5 παραδέιγματα στην αρχική τους μορφή και όπως τα επιστρέφει η κλάση SentenceDataset για κάθε ένα dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __MR dataset__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"photos/EX3_1_MR.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"photos/EX3_2_MR\n",
    ".png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"photos/EX3_3_MR.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"photos/EX3_4_MR.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"photos/EX3_5_MR.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Semeval 2017A dataset__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"photos/EX3_1_Sem.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"photos/EX3_2_Sem.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"photos/EX3_3_Sem.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"photos/EX3_4_Sem.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"photos/EX3_5_Sem.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2> 2. Μοντέλο </h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Σε αυτό το βήμα θα σχεδιάσουμε ένα νευρωνικό δίκτυο, το οποίο:\n",
    "- Θα δημιουργεί μία συνεχή διανυσματική αναπαράσταση για κάθε όρο σε μία πρόταση με την χρήση ενός Embedding layer,\n",
    "- Θα δημιουργεί μία διανυσματική αναπαράσταση για όλο το κείμενο ενός παραδείγματος,\n",
    "- Θα κατηγοριοποιεί το κείμενο βάση της αναπαράστασης του στην σωστή κλάση."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ο πηγαίος κώδικας του μοντέλου βρίσκεται στο αρχείο models.py. Στη μέθοδο init θα δηλώσουμε τα layers του δικτύου και θα αρχικοποιήσουμε τα βάρη τους. Στη μέθοδο forward θα ορίσουμε τους μετασχηματισμούς των δεδομένων εισόδου για την παραγωγή της τελικής εξόδου του μοντέλου (forward pass)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Embedding Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Στο στάδιο αυτό θα δημιουργήσουμε το embedding layer το οποίο παίρνει κάθε όρο/λέξη το προβάλλει σε ένα συνεχή χώρο (embedding space) στον οποίο βρίσκονται κοντά οι νοηματικά κοντινές λέξεις.Τα βάρη του embedding layer μπορούμε να τα αρχικοποιήσουμε με τυχαίες τιμές και να τα ενημερώσουμε κατά την εκπαίδευση του μοντέλου ή να τα αρχικοποιήσουμε από προ-εκπαιδευμένα word embeddings. Εμείς θα κάνουμε το δεύτερο χρησιμοποιώντας τα embeddings που βρίσκονται στον φάκελο /embeddings και συγκεκριμένα τα 50-dimensional Glove embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ελέγχουμε παρακάτω τον κώδικα για την δημιουργία του embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape is:  (4, 5)\n",
      "Embedding array is:  [[0 1 2 3 4]\n",
      " [0 2 4 6 8]\n",
      " [1 3 5 7 9]\n",
      " [4 3 2 1 0]]\n",
      "Input batch shape is:  torch.Size([2, 6])\n",
      "Input batch is:  tensor([[3, 0, 0, 1, 2, 1],\n",
      "        [0, 1, 2, 3, 1, 0]])\n",
      "Output of embedding layer has shape:  torch.Size([2, 6, 5])\n",
      "Output of embedding layer is:  tensor([[[4., 3., 2., 1., 0.],\n",
      "         [0., 1., 2., 3., 4.],\n",
      "         [0., 1., 2., 3., 4.],\n",
      "         [0., 2., 4., 6., 8.],\n",
      "         [1., 3., 5., 7., 9.],\n",
      "         [0., 2., 4., 6., 8.]],\n",
      "\n",
      "        [[0., 1., 2., 3., 4.],\n",
      "         [0., 2., 4., 6., 8.],\n",
      "         [1., 3., 5., 7., 9.],\n",
      "         [4., 3., 2., 1., 0.],\n",
      "         [0., 2., 4., 6., 8.],\n",
      "         [0., 1., 2., 3., 4.]]])\n"
     ]
    }
   ],
   "source": [
    "# ----------------------- #\n",
    "# Embedding layer testing #\n",
    "# ----------------------- #\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "max_length = 6\n",
    "n_embeddings = 4\n",
    "embedding_size = 5\n",
    "# Define a sample embedding array \n",
    "embeddings = np.array([[0, 1, 2, 3, 4],[0, 2, 4, 6, 8], [1, 3, 5, 7, 9], [4, 3, 2, 1, 0]])\n",
    "print(\"Embeddings shape is: \", embeddings.shape)\n",
    "print(\"Embedding array is: \", embeddings)\n",
    "# Define a embedding layer\n",
    "embed = nn.Embedding(num_embeddings = n_embeddings, embedding_dim = embedding_size)\n",
    "# Initialize the weights of the embedding layer with embeddings array.\n",
    "embed.load_state_dict({'weight': torch.from_numpy(embeddings)})\n",
    "# Make embedding layer non-trainable\n",
    "embed.weight.requires_grad = False\n",
    "# create batch with some data\n",
    "x = torch.from_numpy(np.array([[3, 0, 0, 1, 2, 1], [0, 1, 2, 3, 1, 0]])).long()\n",
    "print(\"Input batch shape is: \", x.shape)\n",
    "print(\"Input batch is: \", x)\n",
    "# pass it through the embedding layer\n",
    "embeddings = embed(x)\n",
    "print(\"Output of embedding layer has shape: \", embeddings.shape)\n",
    "print(\"Output of embedding layer is: \", embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ερώτηση 1: Γιατί αρχικοποιούμε το embedding layer με τα προ-εκπαιδευμένα word embeddings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Αυτό συμβαίνει διότι θέλουμε από την αρχή τα embeddings να μην είναι τυχαία. Έτσι, διευκολύνουμε το νευρωνικό μας\n",
    "στο να συγκλίνει κάπου και κάνουμε την εκπαίδευση πιο γρήγορη. Αν αρχικοποιούσαμε το embedding layer με τυχαίες τιμές και το αφήναμε να εκπαιδευτεί κατα το training τότε θα ηταν πολύ πιο δύσκολο για το νευρωνικό να βρει ένα μοτίβο σε αυτά τα unstructered δεδομένα που θα αναπαρηστούν τις λέξεις εντελώς τυχαία στο χώρο. Τα προ-εκπαιδευμένα embeddings τώρα επειδή αναπαριστούν τις λέξεις σε ένα χώρο όπου η σημασιολογικά κοντά λέξεις είναι και κοντά σε αυτό το χώρο (από πλευρά απόστασης) δίνουν στο νευρωνικά πιο δομημένα τα δεδομένα και την πληροφορία ώστε αυτό να εκπαιδευτεί ευκολότερα σε αυτά και να συγκλίνει κάπου."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ερώτηση 2: Γιατί κρατάμε παγωμένα τα βάρη του embedding layer κατά την εκπαίδευση?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Κατά την εκπαίδευση κρατάμε παγωμένα τα βάρη του embedding layer για τους εξής δύο λόγους:\n",
    "- Για να αποφύγουμε το overfitting το οποίο είναι πολύ πιθανό να συμβεί αν εκτός από το νευρωνικό είχαμε και τις\n",
    "αναπαραστάσεις που μπαίνουν σε αυτό να εκπαιδεύονται πάνω στο training set μας. Αυτό θα εμποδίσει τον αλγόριθμο στο να γενικεύσει και θα καταλήξουμε με ένα μοντέλο που απλά έχει μάθει πάρα πολύ καλά τα δεδομένα που του δώσαμε.\n",
    "- Για να μειώσουμε τις συνολικές παραμέτρους του μοντέλου μας κερδίζοντας έτσι σε υπολογιστική πολυπλοκότητα.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Output Layer(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Στη συνέχεια, πρέπει να θα πρέπει να προβάλουμε τις αναπαραστάσεις των κειμένων στο χώρο των κλάσεων. Αυτό θα συμβεί σε δύο στάδια. Αρχικά, θα έχουμε ένα layer με μία μη γραμμική συνάρτηση ενεργοποίησης (relu) και στη συνέχεια θα έχουμε το τελευταίο layer το οποίο θα προβάλει τις τελικές αναπαραστάσεις στον χώρο των κλάσεων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# 2dim tensor.. aka a matrix\n",
    "batch_size = 16\n",
    "feature_size = 5\n",
    "x = torch.randn(batch_size, feature_size)\n",
    "# now let's try out some NN layer\n",
    "output_size = 3\n",
    "fc = nn.Linear(feature_size, output_size)\n",
    "print(fc(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ερώτηση 3: Γιατί βάζουμε μία μη γραμμική συνάρτηση ενεργοποίησης στο προτελευταίο layer? Τι διαφορά θα είχε αν είχαμε 2 ή περισσότερους γραμμικούς μετασχηματισμούς στη σειρά?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Η εισαγωγή μιας μη γραμμικής συνάρτησης ενεργοποιήσης στο προτελευταίο layer γίνεται ώστε να εισάγουμε την μη\n",
    "γραμμικότητα στο μοντέλο και να του δώσουμε την δυνατότητα να κατασκευάζει και μη γραμμικές συναρτήσεις για να\n",
    "περιγράψει την είσοδο. Αν απλά είχαμε 2 ή περισσότερους γραμμικούς μετασχηματισμούς στη σειρά τότε αυτό θα ισοδυναμούσε με ένα απλό perceptron αφού το γινόμενο γραμμικών συναρτήσεων κάνει γραμμική συνάρτηση. Το μοντέλο μας λοιπόν θα προσπαθούσε να περιγράψει την είσοδό του χρησιμοποιώντας μόνο γραμμικές συναρτήσεις (όπως σε ένα απλό logistic regression μοντέλο) και έτσι θα καταλήγαμε με ένα πολύ φτωχό μοντέλο."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Στο σημείο αυτό θα κάνουμε το forward propagation, δηλαδή θα σχεδιάσουμε τον τρόπο με τον οποίο το μοντέλο μας\n",
    "θα μετασχηματίζει μία είσοδο που του δίνουμε στην αντίστοιχη έξοδο. Η είσοδος στο μοντέλο θα είναι ένα mini-batch\n",
    "με διαστάσεις (batch_size, max_length). Η έξοδος θα προκύπτει ως εξής:\n",
    "- Αρχικά, περνάμε τiς λέξεις κάθε πρότασης από το embedding layer ώστε να αντιστοιχηθεί κάθε όρος σε ένα διάνυσμα. \n",
    "- Μετά, πρέπει να δημιουργήσουμε από τις επιμέρους αναπαραστάσεις των όρων μία ενιαία για κάθε πρόταση. Αυτό θα γίνει υπολογίζοντας των μέσο όρων των embeddings σε μία πρόταση.\n",
    "- Το επόμενο βήμα είναι να εφαρμόσουμε τον μη γραμμικό μετασχηματισμό μας στην παραπάνω αναπαράσταση.\n",
    "- Τέλος, προβάλλουμε την τελική αναπαράσταση στον χώρο των κλάσεων."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Επειδή όλα τα παραπάνω είναι αρκετές λειτουργίες εφαρμόζουμε όλα τα παραπάνω για ένα δικό μας μικρό mini-batch λέξεων όπως φαίνεται παρακάτω. Ένας αντίστοιχος κώδικας συμπληρώθηκε και στο αρχείο models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUTS\n",
      "Input batch shape is:  torch.Size([2, 6])\n",
      "Input batch is:  tensor([[3, 0, 0, 1, 2, 1],\n",
      "        [0, 1, 2, 3, 1, 0]])\n",
      "Input lengths array is:  [5 3]\n",
      "STEP 1\n",
      "Output of embedding layer has shape:  torch.Size([2, 6, 5])\n",
      "Output of embedding layer is:  tensor([[[4., 3., 2., 1., 0.],\n",
      "         [0., 1., 2., 3., 4.],\n",
      "         [0., 1., 2., 3., 4.],\n",
      "         [0., 2., 4., 6., 8.],\n",
      "         [1., 3., 5., 7., 9.],\n",
      "         [0., 2., 4., 6., 8.]],\n",
      "\n",
      "        [[0., 1., 2., 3., 4.],\n",
      "         [0., 2., 4., 6., 8.],\n",
      "         [1., 3., 5., 7., 9.],\n",
      "         [4., 3., 2., 1., 0.],\n",
      "         [0., 2., 4., 6., 8.],\n",
      "         [0., 1., 2., 3., 4.]]])\n",
      "Step 2\n",
      "Representation of sentences have shape:  torch.Size([2, 5])\n",
      "Representation of sentences:  tensor([[ 1.0000,  2.4000,  3.8000,  5.2000,  6.6000],\n",
      "        [ 1.6667,  4.0000,  6.3333,  8.6667, 11.0000]])\n",
      "Step 3\n",
      "Output of layer 1 have shape:  torch.Size([2, 8])\n",
      "Output of layer 1:  tensor([[2.4996, 0.7802, 2.0321, 0.0000, 0.0000, 3.7189, 1.2986, 0.0000],\n",
      "        [4.2346, 1.0812, 3.1754, 0.0000, 0.0000, 6.2130, 2.2439, 0.0000]],\n",
      "       grad_fn=<ThresholdBackward0>)\n",
      "Step 4\n",
      "Output have shape:  torch.Size([2, 3])\n",
      "Output:  tensor([[ 0.4678, -0.3922,  0.4258],\n",
      "        [ 0.6168, -0.5789,  0.3995]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# -------------------- #\n",
    "# Forward pass testing #\n",
    "# -------------------- #\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# Lengths definitions\n",
    "max_length = 6\n",
    "n_embeddings = 4\n",
    "batch_size = 2\n",
    "embeddings_size = 5\n",
    "hidden_size = 8\n",
    "\n",
    "# Create batch with some data\n",
    "x = torch.from_numpy(np.array([[3, 0, 0, 1, 2, 1], [0, 1, 2, 3, 1, 0]])).long()\n",
    "# Create the lengths array\n",
    "lengths = np.array([5, 3])\n",
    "print(\"INPUTS\")\n",
    "print(\"Input batch shape is: \", x.shape)\n",
    "print(\"Input batch is: \", x)\n",
    "print(\"Input lengths array is: \", lengths)\n",
    "\n",
    "# 1. pass it through the embedding layer that we created in the 'Embedding layer' section.\n",
    "embeddings = embed(x)\n",
    "print(\"STEP 1\")\n",
    "print(\"Output of embedding layer has shape: \", embeddings.shape)\n",
    "print(\"Output of embedding layer is: \", embeddings)\n",
    "\n",
    "# 2. Create a representiation for each sentence by computing the mean of the word embeddings in each .\n",
    "representations = torch.zeros([batch_size, embeddings_size])\n",
    "for i in range(batch_size):\n",
    "    representations[i] = torch.sum(embeddings[i], dim=0) / lengths[i]\n",
    "print(\"Step 2\")\n",
    "print(\"Representation of sentences have shape: \", representations.shape)\n",
    "print(\"Representation of sentences: \", representations)\n",
    "\n",
    "# 3. Pass it through non linear transformation\n",
    "linear1 = nn.Linear(embedding_size, hidden_size)\n",
    "relu = nn.ReLU()\n",
    "representations =  relu(linear1(representations))\n",
    "print(\"Step 3\")\n",
    "print(\"Output of layer 1 have shape: \", representations.shape)\n",
    "print(\"Output of layer 1: \", representations)\n",
    "# 4 - Project the representations to classes using a linear layer\n",
    "linear2 = nn.Linear(hidden_size, output_size)\n",
    "logits = linear2(representations)\n",
    "print(\"Step 4\")\n",
    "print(\"Output have shape: \", logits.shape)\n",
    "print(\"Output: \", logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ερώτηση 4: Αν θεωρήσουμε ότι κάθε διάσταση του embedding χώρου αντιστοιχεί σε μία αφηρημένη έννοια, μπορείτε να δώσετε μία διαισθητική ερμηνεία για το τι περιγράφει η αναπαράσταση που φτιάξατε (κέντρο-βάρους)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Στο μοντέλο μας η αναπαράσταση μίας πρότασης προέκυψε ως το κέντρο βάρους των embeddings των λέξεων που την απαρτίζουν. Συνεπώς, η τιμή σε κάθε διάσταση της τελικής αναπαράστασης αποτελεί τον μέρο όρο των τιμών των λέξεων σε αυτή στη διάσταση. Αυτό σημαίνει, ότι αναπαράσταση μας εκφράζει μία έννοια όταν οι λέξεις που την απαρτίζουν εκφράζουν επίσης αυτήν την έννοια και αντίστοιχα δεν εκφράζει μία έννοια όταν οι λέξεις που την απαρτίζουν δεν την εκφράζουν και αυτές. Αυτό είναι σωστό προφανώς ότι δηλαδή το νόημα μιας πρότασης προκύπτει άμεσα από το νόημα των λέξεων που την απαρτίζουν, ωστόσο η αναπαράσταση αυτή δεν λαμβάνει υπόψιν της τα συντακτικά χαρακτηριστικά."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ερώτηση 5: Αναφέρετε πιθανές αδυναμίες της συγκεκριμένης προσέγγισης για να αναπαραστήσουμε κείμενα. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Η κύρια αδυναμία της συγκεκριμένης προσέγγισης είναι ότι αγνοούμε τελείως την σειρά με την οποία έρχονται οι λέξεις και απλά τις αντιμετωπίζουμε ως μέρος της πρότασης είτε βρίσκονται στην αρχή, είτε στη μέση, είτε στο τέλος. Αυτό είναι μεγάλη αδυναμία γιατί τα συντακτικά χαρακτηριστικά μιας πρότασης πολλές φορές επηρεάζουν την\n",
    "σημασία της.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2> 3. Διαδικασία Εκπαίδευσης </h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Σε αυτό το βήμα θα υλοποιήσουμε την διαδικασία εκπαίδευσης του δικτύου, όπως να οργανώσουμε τα παραδείγματα σε mini-batches και να εκτελέσουμε stochastic gradient descent για να ενημερώνουμε τα βάρη του δικτύου."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Φόρτωση Παραδειγμάτων (DataLoaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Χρησιμοποιούμε την κλάση DataLoader η οποία μας επιτρέπει να χωρίζουμε το data set σε mini-batches και γενικά μας επιστρέπει λειτουργίες πάνω σε ένα set δεδομένων."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ερώτηση 6: Τι συνέπειες έχουν τα μικρά και μεγάλα mini-batches στην εκπαίδευση των μοντέλων?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Το μέγεθος των mini-batches επηρεάζει την εκπαίδευση των μοντέλων μας με δύο τρόπους. Αρχικά, στο SGD όταν πηγαίνουμε να υπολογίσουμε τα gradients όσο πιο μεγάλο mini-batch έχουμε τόσο πιο κοντά είμαστε στα gradients όλου του training set και δεν έχουμε εισάγει θόρυβο στο μοντέλο μας. Αυτό όμως δεν είναι συνήθως θετικό γιατί το μοντέλο με τα μεγάλα mini-batch ίσως συγκλίνει σε κάποιο τοπικό ελάχιστο το οποίο ένα αντίστοιχο μοντέλο αλλά με μικρότερα mini-batches (επειδή ακριβώς θα είχε εισάγει θόρυβο) ίσως να είχε ξεπηδήσει από αυτό και να κατέληγε στο ολικό ελάχιστο. Ακόμη, όταν έχουμε μικρά mini-batches τότε το update των βαρών κάθε φορά γίνεται πιο γρήγορα και μπορούμε να έχουμε μια πιο άμεση εικόνα για το τι συμβαίνει στο μοντέλο μας."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ερώτηση 7:Συνήθως ανακατεύουμε την σειρά των mini-batches στα δεδομένα εκπαίδευσης σε κάθε εποχή.Μπορείτε να εξηγήσετε γιατί?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Το shuffling στα δεδομένα μας μετά από κάθε εποχή γίνετια για τους εξής δύο λόγους:\n",
    "- Το μοντέλο μας έχει την δυνάτοτητα να μαθαίνει περίπλοκες μη γραμμικές συναρτήσεις της εξόδου συνάρτηση της εισόδου. Αυτό σημαίνει ότι υπάρχει περίπτωση να μάθε ακόμα και την σειρά με την οποία έρχονται τα δεδομένα σε αυτό. Όταν αυτό δεν το θέλουμε, η λύση είναι να ανακατεύουμε τα mini-batches σε κάθε εποχή έτσι ώστε κάθε φορά το νευρωνικό να τα βλέπει με διαφορετική σειρά και να μην λάβει υπόψιν τη σειρά καθώς εκπαιδεύεται.\n",
    "- Όταν αλλάζουμε συνεχώς την σειρά με την οποία έρχονται τα mini-batches αυτό μποτεί να οδηγήσει σε πιο εύκολη σύγκλιση στο ολικό ελάχιστο. Αυτό συμβαίνει διότι δίνουμε διαρκώς στο νευρωνικό διαφορετικά δεδομένα και έτσι σε περίπτωση που κολλήσει σε κάποιο τοπικό ελάχιστο κατά την εκπαίδευση είναι πολύ πιθανό να ξεκολλήσει στην επόμενη επανάληψη."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Βελτιστοποίηση"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Για την βελτιστοποίηση του μοντέλου μας πρέπει να ορίσουμε τα εξής:\n",
    "- Κριτήριο. Αν το πρόβλημα κατηγοριοποίησης έχει 2 κλάσεις τότε χρησιμοποιούμε το BCEWithLogitsLoss, ενώ αν έχει περισσότερες τότε χρησιμοποιούμε το CrossEntropyLoss.\n",
    "- Παράμετροι. Επιλέγουμε τις παραμέτρους οι οποίες θα βελτιστοποιηθούν οι οποίες είναι όσες έχει true στο πεδίο requires_grad ώστε να υπολογιστεί ο gradient στο backpropagation.\n",
    "- Optimizer. Επιλέγουμε τον αλγόριθμο βελτιστοποίησης Adam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Εκπαίδευση"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Το τελευταίο βήμα για την εκπαίδευση του μοντέλου, είναι να υλοποιήσομυε τις μεθόδους για την εκπαίδευση και αξιολόγηση κάθε mini-batch. H συνάρτηση train dataset καλείται για κάθε batch σε μία εποχή, δίνει τα δεδομένα εκπαίδευσης στο μοντέλο, υπολογίζει το σφάλμα και ενημερώνει τα βάρη του δικτύου με τον αλγόριθμο backpropagation. Ομοίως, η συνάρτηση eval dataset καλείται στο τέλος κάθε εποχής, για να αξιολογήσει το μοντέλο. Επειδή, τα βήματα είναι πολύ συγκεκριμένα δεν χρειάζεται να ελέγξουμε όπως προηγουμένως το συγκεκριμένο βήμα οπότε ο κώδικας έχει συμπληρωθεί στο training.py με αναλυτικά σχόλια."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Αξιολόγηση"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Γενικά για να τρέξει κανείς το τελικό πρόγραμμα πρέπει να ακολουθήσει τα εξής βήματα:\n",
    "- Να ορίσει στα αρχεία main.py, training.py, dataloading.py πάνω σε ποιο από τα δύο dataset(μεταβλητή DATASET με επιλογές MR ή Semevel2017A) επιθυμεί να εκπαιδεύσει το μοντέλο του.\n",
    "- Να ορίσει στο αρχέιο main.py ποιό embedding επιθυμεί να χρησιμοποιήσει από τα διαθέσιμα στον φάκελο /embeddings (μεταβλητή EMBEDDINGS και EMB_DIM).\n",
    "- Να τρέξει __python main.py__. Στο stdout θα εμφανιστούν σε κάθε εποχή οι ζητούμενες μετρικές του μοντέλου και στο τέλος θα εμφανιστούν οι δύο γραφικές παραστάσεις (loss του train και του test set)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Για τον υπολογισμό διάφορων μετρικών του μοντέλου χρησιμοποιήθηκε η βιβλιοθήκη sklearn.metrics. Παρακάτω φαίνονται τα αποτελέσματα ενώ στον κώδικα υπάρχουν αναλυτικά σχόλια. Όλα εκπαιδεύτηκαν για 50 εποχές οι οποίες προκαλούν σχεδόν πάντα overfit οπότε από το διάγραμμα κάθε φορά μπορούμε να δούμε σε ποια εποχή θα έπρεπε ίσως να έχουμε σταματήσει την εκπαίδευση."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3> Sentence Polarity Dataset (MR)</h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### glove.6B.50d embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "    <td> <img src=\"photos/results/MR/train_MR_50dGlove.png\" alt=\"Drawing\" style=\"width: \"/> </td>\n",
    "    <td> <img src=\"photos/results/MR/test_MR_50dGlove.png\" alt=\"Drawing\" style=\"width: \"/> </td>\n",
    "    </tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"photos/results/MR/out_MR_50dGlove.png\" alt=\"Drawing\" style=\"width: \"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Παρατηρούμε ότι οι default εποχές είναι πάρα πολλές καθώς το loss του test set αρχίζει να αυξάνεται μετά από ένα σημείο γεγονός που οφείλεται στο overfit που κάνει το μοντέλο στα training δεδομένα μας (γι' αυτό και το loss του train set συνεχώς μειώνεται). Αυτό θα συμβαίνει και στα υπόλοιπα μοντέλα και από τις γραφικές καταλαβαίνουμε ότι η εκπαίδευση έπρεπε να σταματήσει σε ένα σημείο όπου το test set θα είχε σταματήσει να βελτιώνεται και απλά θα βελτιωνόταν το train set(για να αποφύγουμε το overfit)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### glove.6B.300d embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "    <td> <img src=\"photos/results/MR/train_MR_300dGlove.png\" alt=\"Drawing\" style=\"width: \"/> </td>\n",
    "    <td> <img src=\"photos/results/MR/test_MR_300dGlove.png\" alt=\"Drawing\" style=\"width: \"/> </td>\n",
    "    </tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"photos/results/MR/out_MR_300dGlove.png\" alt=\"Drawing\" style=\"width: \"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### wiki-news-300d-1M embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "    <td> <img src=\"photos/results/MR/train_MR_wiki.png\" alt=\"Drawing\" style=\"width: \"/> </td>\n",
    "    <td> <img src=\"photos/results/MR/test_MR_wiki.png\" alt=\"Drawing\" style=\"width: \"/> </td>\n",
    "    </tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"photos/results/MR/out_MR_wiki300d.png\" alt=\"Drawing\" style=\"width: \"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3> Semeval 2017 Task4-A</h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### glove.twitter.27B.25d embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "    <td> <img src=\"photos/results/Semeval2017A/train_Sem_tweet25d.png\" alt=\"Drawing\" style=\"width: \"/> </td>\n",
    "    <td> <img src=\"photos/results/Semeval2017A/test_Sem_tweet25d.png\" alt=\"Drawing\" style=\"width: \"/> </td>\n",
    "    </tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"photos/results/Semeval2017A/out_Sem_25dTweet.png\" alt=\"Drawing\" style=\"width: \"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### glove.twitter.27B.50d embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "    <td> <img src=\"photos/results/Semeval2017A/train_Sem_tweet50d.png\" alt=\"Drawing\" style=\"width: \"/> </td>\n",
    "    <td> <img src=\"photos/results/Semeval2017A/test_Sem_tweet50d.png\" alt=\"Drawing\" style=\"width: \"/> </td>\n",
    "    </tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"photos/results/Semeval2017A/out_Sem_tweet50d.png\" alt=\"Drawing\" style=\"width: \"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### glove.twitter.27B.100d embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "    <td> <img src=\"photos/results/Semeval2017A/train_Sem_tweet100d.png\" alt=\"Drawing\" style=\"width: \"/> </td>\n",
    "    <td> <img src=\"photos/results/Semeval2017A/test_Sem_tweet100d.png\" alt=\"Drawing\" style=\"width: \"/> </td>\n",
    "    </tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"photos/results/Semeval2017A/out_Sem_100dtweet.png\" alt=\"Drawing\" style=\"width: \"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### glove.twitter.27B.200d embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "    <td> <img src=\"photos/results/Semeval2017A/train_Sem_tweet200d.png\" alt=\"Drawing\" style=\"width: \"/> </td>\n",
    "    <td> <img src=\"photos/results/Semeval2017A/test_Sem_tweet200d.png\" alt=\"Drawing\" style=\"width: \"/> </td>\n",
    "    </tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"photos/results/Semeval2017A/out_Sem_tweet200d.png\" alt=\"Drawing\" style=\"width: \"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Σαν μια γενική παρατήρηση για τα αποτελέσματα είναι ότι όσο καλύτερα embeddings βάζαμε τόσο καλύτερο ήταν το μοντέλο μας απλά έκανε overfit πάρα πολύ γρήγορα και το test loss αυξανόταν. Στο πρώτο dataset το τελευταίο embedding έβγαλε τα καλύτερα αποτελέσματα αφού φάνηκε να μην κάνει overfit μειώνοντας παράλληλα δραματικά το train loss. Στο δεύτερο (όπου επιλέχθηκαν τα embeddings που είναι εκπαιδευμένα σε tweets) όλα τα μοντέλα μετά από την 20-30 εποχή κάνανε overfit αλλά τα αποτελέσματα (αν λάβουμε υπόψιν το απλό tokenize που κάναμε αλλά και το ότι έχουμε ένα απλό nn χωρίς εξελιγμένες τεχνικές) είναι ικανοποιητικά. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
